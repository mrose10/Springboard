{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Datacamp Image Processing\n",
    "#### Example code to remember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "grayscale = color.rgb2gray(original)\n",
    "\n",
    "def show_image(image, title='Image', cmap_type='gray'):\n",
    "    plt.imshow(image,cmap=cmap_type)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# Use numpy to flip    \n",
    "import numpy as np\n",
    "\n",
    "# Flip the image\n",
    "vertically_flipped = np.flipud(original)\n",
    "horizontally_flipped = np.fliplr(original)\n",
    "\n",
    "#Matplotlib has hist function\n",
    "plt.hist(original.ravel(), bines = 256) # unravel the image to a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering\n",
    "There are other options. Local options require a block size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Get threshold values\n",
    "thresh = threshold_otsu(gray_image) #Otsu finds global optimum threshold\n",
    "\n",
    "# Apply threshold\n",
    "binary_global = gray_image > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morphology and Edge Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilation and erosion, binary_dilation and binary_erosion\n",
    "from skimage import morphology\n",
    "\n",
    "# Edge detection\n",
    "from skimage.filters import sobel\n",
    "\n",
    "#Gaussion smoothing\n",
    "from skimage.filters import gaussion\n",
    "\n",
    "#Need multichannel for colored images\n",
    "gaussian_image = gaussian(image, multichannel = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrast and histogram equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "#Histogram equalization\n",
    "image_eq = exposure.equalize_hist(image) \n",
    "\n",
    "#CLAHE\n",
    "image_adapteq = exposure.equalize_adapthist(image, clip_limit=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "from skimage.restoration import denoise_tv_chambolle, denoise_bilateral\n",
    "#denoise_bilateral - better preserves edges over chambolle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the slic function from segmentation module\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "# Import the label2rgb function from color module\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "# Obtain the segmentation with 400 regions\n",
    "segments = slic(face_image, n_segments= 400)\n",
    "\n",
    "# Put segments on top of original image to compare\n",
    "segmented_image = label2rgb(segments,face_image, kind='avg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "# Make the image grayscale\n",
    "image_dices = color.rgb2gray(image_dices)\n",
    "\n",
    "# Obtain the optimal thresh value\n",
    "thresh = filters.threshold_otsu(image_dices)\n",
    "\n",
    "# Apply thresholding\n",
    "binary = image_dices > thresh\n",
    "\n",
    "# Find contours at a constant value of 0.8\n",
    "contours = measure.find_contours(binary, level=0.8)\n",
    "\n",
    "# Show the image\n",
    "show_image_contour(image_dices, contours)\n",
    "\n",
    "shape_contours = [cnt.shape[0] for cnt in contours]\n",
    "\n",
    "# Count dots in contours excluding bigger than dots size\n",
    "dots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < max_dots_shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the canny edge detector \n",
    "from skimage.feature import canny\n",
    "# canny is faster than sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the corner detector related functions and module\n",
    "from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "# Convert image from RGB-3 to grayscale\n",
    "building_image_gray = color.rgb2gray(building_image)\n",
    "\n",
    "# Apply the detector  to measure the possible corners\n",
    "measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "# Find the peaks of the corners using the Harris detector\n",
    "coords = corner_peaks(measure_image, min_distance=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face detection and window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output gives  dictionary ['r','c','width','height']\n",
    "\n",
    "def show_detected_face(result, detect, title=\"Face image\"):\n",
    "    plt.imshow(result)\n",
    "    img_desc = plt.gca()\n",
    "    plt.set_cmap('gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    for patch in detected:\n",
    "        img_desc.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (patch['c'], patch['r']),\n",
    "                patch['width'],\n",
    "                patch['height'],\n",
    "                fill=False, color = 'r', linewidth =2)\n",
    "        )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained file from data\n",
    "trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "# Initialize the detector cascade\n",
    "detector = Cascade(trained_file)\n",
    "\n",
    "# Detect faces with min and max size of searching window\n",
    "detected = detector.detect_multi_scale(img = night_image,\n",
    "                                       scale_factor=1.2,\n",
    "                                       step_ratio=1,\n",
    "                                       min_size=(10,10),\n",
    "                                       max_size=(200,200))\n",
    "\n",
    "\n",
    "# Show the detected faces\n",
    "show_detected_face(night_image, detected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
